{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part_1.mat',\n",
       " 'part_10.mat',\n",
       " 'part_11.mat',\n",
       " 'part_12.mat',\n",
       " 'part_2.mat',\n",
       " 'part_3.mat',\n",
       " 'part_4.mat',\n",
       " 'part_5.mat',\n",
       " 'part_6.mat',\n",
       " 'part_7.mat',\n",
       " 'part_8.mat',\n",
       " 'part_9.mat',\n",
       " 'Samples']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import numpy as np  # For numerical computation\n",
    "import pandas as pd  # Data manipulation\n",
    "import seaborn as sns  # plotting\n",
    "import scipy.io  # reading matlab files in python\n",
    "from scipy import signal  #signal processing\n",
    "from scipy.fftpack import fft, dct  #signal processing\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  #linear regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split  # cross validation split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pyplot as plt  # For plotting graphs(Visualization)\n",
    "\n",
    "import os  # system-wide functions\n",
    "\n",
    "os.listdir('./kaggle_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our evaluation error function\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Computes the Root Mean Squared Error (RMSE).\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_file Data type: <class 'dict'>\n",
      "sample_file keys:\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'p'])\n"
     ]
    }
   ],
   "source": [
    "sample_file = scipy.io.loadmat(f'./kaggle_data/part_{1}.mat')\n",
    "print(f'sample_file Data type: {type(sample_file)}')\n",
    "print(f'sample_file keys:\\n{sample_file.keys()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sample Data type: <class 'numpy.ndarray'>\n",
      "test_sample shape/dimensions: (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Loading a sample .mat file to understand the data dimensions\n",
    "test_sample = scipy.io.loadmat(f'./kaggle_data/part_{1}.mat')['p']\n",
    "print(f'test_sample Data type: {type(test_sample)}')\n",
    "print(f'test_sample shape/dimensions: {test_sample.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 1000\n",
      "Number of readings in each sample(column): 3\n",
      "Number of samples in each reading(ECG): 61000\n",
      "9000\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Samples: {len(test_sample[0])}\")\n",
    "print(f\"Number of readings in each sample(column): {len(test_sample[0][0])}\")\n",
    "print(f\"Number of samples in each reading(ECG): {len(test_sample[0][0][2])}\")\n",
    "\n",
    "temp_mat = test_sample[0, 999]\n",
    "temp_length = temp_mat.shape[1]\n",
    "sample_size = 125\n",
    "\n",
    "print(temp_length)\n",
    "print((int)(temp_length / sample_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 125\n",
    "ppg = []\n",
    "for i in range(1000):\n",
    "    temp_mat = test_sample[0, i]\n",
    "    temp_length = temp_mat.shape[1]\n",
    "    for j in range((int)(temp_length / sample_size)):\n",
    "        temp_ppg = temp_mat[0, j * sample_size:(j + 1) * sample_size]\n",
    "        ppg.append(temp_ppg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg = []\n",
    "bp = []\n",
    "sbp = []  #Systolic Blood Pressure\n",
    "dbp = []  #Diastolic Blood Pressue\n",
    "size = 125  #sample size\n",
    "\n",
    "for i in range(1000):\n",
    "    temp_mat = test_sample[0, i]\n",
    "    temp_length = temp_mat.shape[1]\n",
    "    for j in range((int)(temp_length / sample_size)):\n",
    "        temp_ecg = temp_mat[2, j * size:(j + 1) * size]\n",
    "        temp_bp = temp_mat[1, j * size:(j + 1) * size]\n",
    "\n",
    "        max_value = max(temp_bp)\n",
    "        min_value = min(temp_bp)\n",
    "\n",
    "        sbp.append(max_value)\n",
    "        dbp.append(min_value)\n",
    "        ecg.append(temp_ecg)\n",
    "        bp.append(temp_bp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPG_shape: (32061000, 1)\n",
      " ECG_shape: (32061000, 1)\n",
      " BP_shape: (32061000, 1)\n",
      "Systolic-BP_shape: (256488, 1),\n",
      " Diastolic-BP_shape: (256488, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the ecg, ppg and bp signal data into column vectors\n",
    "ppg, ecg, bp = np.array(ppg).reshape(-1,1), np.array(ecg).reshape(-1,1), np.array(bp).reshape(-1,1)\n",
    "sbp, dbp = np.array(sbp).reshape(-1,1), np.array(dbp).reshape(-1,1)\n",
    "print(f'PPG_shape: {ppg.shape}\\n ECG_shape: {ecg.shape}\\n BP_shape: {bp.shape}')\n",
    "print(f'Systolic-BP_shape: {sbp.shape},\\n Diastolic-BP_shape: {dbp.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pycaret Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.concatenate((ppg, bp), axis=1))\n",
    "data.columns = ['PPG', 'BP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPG</th>\n",
       "      <th>BP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.759531</td>\n",
       "      <td>67.062955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.718475</td>\n",
       "      <td>69.358628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.684262</td>\n",
       "      <td>75.366453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.657869</td>\n",
       "      <td>85.037586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.637341</td>\n",
       "      <td>96.222885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060995</th>\n",
       "      <td>1.413490</td>\n",
       "      <td>123.135987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060996</th>\n",
       "      <td>1.400782</td>\n",
       "      <td>120.889158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060997</th>\n",
       "      <td>1.386119</td>\n",
       "      <td>118.495797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060998</th>\n",
       "      <td>1.368524</td>\n",
       "      <td>116.053592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060999</th>\n",
       "      <td>1.352884</td>\n",
       "      <td>113.611387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32061000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PPG          BP\n",
       "0         1.759531   67.062955\n",
       "1         1.718475   69.358628\n",
       "2         1.684262   75.366453\n",
       "3         1.657869   85.037586\n",
       "4         1.637341   96.222885\n",
       "...            ...         ...\n",
       "32060995  1.413490  123.135987\n",
       "32060996  1.400782  120.889158\n",
       "32060997  1.386119  118.495797\n",
       "32060998  1.368524  116.053592\n",
       "32060999  1.352884  113.611387\n",
       "\n",
       "[32061000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (100, 2))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train-test set of 70 and 30 percent respectively\n",
    "train = data[data.index < 1000]\n",
    "test = data[data.index >= 32060900]\n",
    "\n",
    "# check shape\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0.rc3\n",
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import pycaret\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(pycaret.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.time_series import TSForecastingExperiment\n",
    "exp = TSForecastingExperiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Figure Settings for notebook ----\n",
    "global_fig_settings = {\"renderer\": \"notebook\", \"width\": 1000, \"height\": 600}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9c2d7_row22_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9c2d7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9c2d7_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_9c2d7_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9c2d7_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_9c2d7_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9c2d7_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_9c2d7_row1_col1\" class=\"data row1 col1\" >BP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9c2d7_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_9c2d7_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9c2d7_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_9c2d7_row3_col1\" class=\"data row3 col1\" >Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9c2d7_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_9c2d7_row4_col1\" class=\"data row4 col1\" >(1000, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9c2d7_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_9c2d7_row5_col1\" class=\"data row5 col1\" >(1000, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_9c2d7_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_9c2d7_row6_col1\" class=\"data row6 col1\" >(999, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_9c2d7_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_9c2d7_row7_col1\" class=\"data row7 col1\" >(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_9c2d7_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_9c2d7_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_9c2d7_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_9c2d7_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_9c2d7_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_9c2d7_row10_col1\" class=\"data row10 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_9c2d7_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_9c2d7_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_9c2d7_row12_col0\" class=\"data row12 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_9c2d7_row12_col1\" class=\"data row12 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_9c2d7_row13_col0\" class=\"data row13 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_9c2d7_row13_col1\" class=\"data row13 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_9c2d7_row14_col0\" class=\"data row14 col0\" >Seasonalities Detected</td>\n",
       "      <td id=\"T_9c2d7_row14_col1\" class=\"data row14 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_9c2d7_row15_col0\" class=\"data row15 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_9c2d7_row15_col1\" class=\"data row15 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_9c2d7_row16_col0\" class=\"data row16 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_9c2d7_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_9c2d7_row17_col0\" class=\"data row17 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_9c2d7_row17_col1\" class=\"data row17 col1\" >No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_9c2d7_row18_col0\" class=\"data row18 col0\" >Recommended d</td>\n",
       "      <td id=\"T_9c2d7_row18_col1\" class=\"data row18 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_9c2d7_row19_col0\" class=\"data row19 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_9c2d7_row19_col1\" class=\"data row19 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_9c2d7_row20_col0\" class=\"data row20 col0\" >Preprocess</td>\n",
       "      <td id=\"T_9c2d7_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_9c2d7_row21_col0\" class=\"data row21 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_9c2d7_row21_col1\" class=\"data row21 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_9c2d7_row22_col0\" class=\"data row22 col0\" >Use GPU</td>\n",
       "      <td id=\"T_9c2d7_row22_col1\" class=\"data row22 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_9c2d7_row23_col0\" class=\"data row23 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_9c2d7_row23_col1\" class=\"data row23 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_9c2d7_row24_col0\" class=\"data row24 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_9c2d7_row24_col1\" class=\"data row24 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c2d7_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_9c2d7_row25_col0\" class=\"data row25 col0\" >USI</td>\n",
       "      <td id=\"T_9c2d7_row25_col1\" class=\"data row25 col1\" >e354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1da4382a310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.time_series.forecasting.oop.TSForecastingExperiment at 0x1da43826280>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.setup(data=train,\n",
    "          target='BP',\n",
    "          seasonal_period=1,\n",
    "          use_gpu=True,\n",
    "          session_id=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_97907\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d981437670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = exp.compare_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to save the results\n"
     ]
    }
   ],
   "source": [
    "# Save the results from the experiment\n",
    "try:\n",
    "    best.to_csv('best.csv')\n",
    "except:\n",
    "    try:\n",
    "        with open('best.csv', 'w') as f:\n",
    "            f.write(best)\n",
    "    except:\n",
    "        print('Failed to save the results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\bunnies\\lib\\site-packages\\pycaret\\time_series\\forecasting\\oop.py:3711\u001b[0m, in \u001b[0;36mTSForecastingExperiment.plot_model\u001b[1;34m(self, estimator, plot, return_fig, return_data, verbose, display_format, data_kwargs, fig_kwargs, save)\u001b[0m\n\u001b[0;32m   3708\u001b[0m system \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mPYCARET_TESTING\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3709\u001b[0m system \u001b[39m=\u001b[39m system \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 3711\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_model(\n\u001b[0;32m   3712\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   3713\u001b[0m     plot\u001b[39m=\u001b[39;49mplot,\n\u001b[0;32m   3714\u001b[0m     return_fig\u001b[39m=\u001b[39;49mreturn_fig,\n\u001b[0;32m   3715\u001b[0m     return_data\u001b[39m=\u001b[39;49mreturn_data,\n\u001b[0;32m   3716\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   3717\u001b[0m     display_format\u001b[39m=\u001b[39;49mdisplay_format,\n\u001b[0;32m   3718\u001b[0m     data_kwargs\u001b[39m=\u001b[39;49mdata_kwargs,\n\u001b[0;32m   3719\u001b[0m     fig_kwargs\u001b[39m=\u001b[39;49mfig_kwargs,\n\u001b[0;32m   3720\u001b[0m     save\u001b[39m=\u001b[39;49msave,\n\u001b[0;32m   3721\u001b[0m     system\u001b[39m=\u001b[39;49msystem,\n\u001b[0;32m   3722\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\bunnies\\lib\\site-packages\\pycaret\\time_series\\forecasting\\oop.py:3162\u001b[0m, in \u001b[0;36mTSForecastingExperiment._plot_model\u001b[1;34m(self, estimator, plot, return_fig, return_data, verbose, display_format, data_kwargs, fig_kwargs, system, save)\u001b[0m\n\u001b[0;32m   3159\u001b[0m     plot \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforecast\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3161\u001b[0m data_types_requested \u001b[39m=\u001b[39m data_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mplot_data_type\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 3162\u001b[0m data_types_to_plot \u001b[39m=\u001b[39m _get_data_types_to_plot(\n\u001b[0;32m   3163\u001b[0m     plot\u001b[39m=\u001b[39;49mplot, data_types_requested\u001b[39m=\u001b[39;49mdata_types_requested\n\u001b[0;32m   3164\u001b[0m )\n\u001b[0;32m   3166\u001b[0m data, data_label, X, X_labels, cv, model_results, model_labels \u001b[39m=\u001b[39m (\n\u001b[0;32m   3167\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3168\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3173\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3174\u001b[0m )\n\u001b[0;32m   3176\u001b[0m include \u001b[39m=\u001b[39m data_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minclude\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\bunnies\\lib\\site-packages\\pycaret\\internal\\plots\\utils\\time_series.py:1065\u001b[0m, in \u001b[0;36m_get_data_types_to_plot\u001b[1;34m(plot, data_types_requested)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[39m#### Get default if not provided ----\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[39mif\u001b[39;00m data_types_requested \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1064\u001b[0m     \u001b[39m# First one is the default\u001b[39;00m\n\u001b[1;32m-> 1065\u001b[0m     data_types_requested \u001b[39m=\u001b[39m [ALLOWED_PLOT_DATA_TYPES\u001b[39m.\u001b[39;49mget(plot)[\u001b[39m0\u001b[39;49m]]\n\u001b[0;32m   1067\u001b[0m \u001b[39m#### Convert string to list ----\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_types_requested, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "exp.plot_model(plot = 'auc', save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot = 'confusion_matrix', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot='vc', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpret model\n",
    "exp.interpret_model(plot = 'correlation', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test / hold-out Sample\n",
    "predict_holdout = exp.predict_model(best, data=test)\n",
    "\n",
    "# Save the predictions in a csv file\n",
    "predict_holdout.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with name from exp.compare_models() top row\n",
    "exp.save_model(best, 'best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML for Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the experiment\n",
    "FH = 48\n",
    "metric = \"mase\"\n",
    "exclude = [\"auto_arima\", \"bats\", \"tbats\", \"lar_cds_dt\", \"par_cds_dt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_auto = TSForecastingExperiment()\n",
    "\n",
    "# enforce_exogenous=False --> Use multivariate forecasting when model supports it, else use univariate forecasting\n",
    "exp_auto.setup(data=train,\n",
    "               target='BP',\n",
    "               fh=FH,\n",
    "               seasonal_period=125,\n",
    "               use_gpu=True,\n",
    "               enforce_exogenous=False,\n",
    "               numeric_imputation_target=\"ffill\",\n",
    "               numeric_imputation_exogenous=\"ffill\",\n",
    "               fig_kwargs=global_fig_settings,\n",
    "               session_id=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include slower models like Prophet (turbo=False), but exclude some specific models ----\n",
    "best_auto = exp_auto.compare_models(sort=metric, turbo=False, exclude=exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results from the experiment\n",
    "try:\n",
    "    best_auto.to_csv('best.csv')\n",
    "except:\n",
    "    try:\n",
    "        with open('best.csv', 'w') as f:\n",
    "            f.write(best_auto)\n",
    "    except:\n",
    "        print('Failed to save the results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_auto_model = exp_auto.finalize_model(best_auto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_predict(exp, model):\n",
    "    \"\"\"Prediction wrapper for demo purposes.\"\"\"\n",
    "    try:\n",
    "        future_preds = exp.predict_model(model)\n",
    "    except ValueError as exception:\n",
    "        print(exception)\n",
    "        exog_vars = exp.exogenous_variables\n",
    "        print(\n",
    "            f\"{len(exog_vars)} exogenous variables (X) needed in order to make future predictions:\\n{exog_vars}\"\n",
    "        )\n",
    "\n",
    "        exog_exps = []\n",
    "        exog_models = []\n",
    "        for exog_var in exog_vars:\n",
    "            exog_exp = TSForecastingExperiment()\n",
    "            exog_exp.setup(data=data[exog_var],\n",
    "                           fh=FH,\n",
    "                           numeric_imputation_target=\"ffill\",\n",
    "                           numeric_imputation_exogenous=\"ffill\",\n",
    "                           fig_kwargs=global_fig_settings,\n",
    "                           session_id=42)\n",
    "\n",
    "            # Users can customize how to model future exogenous variables i.e. add\n",
    "            # more steps and models to potentially get better models at the expense\n",
    "            # of higher modeling time.\n",
    "            best = exog_exp.compare_models(sort=metric,\n",
    "                                           include=[\n",
    "                                               \"arima\",\n",
    "                                               \"ets\",\n",
    "                                               \"exp_smooth\",\n",
    "                                               \"theta\",\n",
    "                                               \"lightgbm_cds_dt\",\n",
    "                                           ])\n",
    "            final_exog_model = exog_exp.finalize_model(best)\n",
    "\n",
    "            exog_exps.append(exog_exp)\n",
    "            exog_models.append(final_exog_model)\n",
    "\n",
    "        # Step 2: Get future predictions for exog variables ----\n",
    "        future_exog = [\n",
    "            exog_exp.predict_model(exog_model)\n",
    "            for exog_exp, exog_model in zip(exog_exps, exog_models)\n",
    "        ]\n",
    "        future_exog = pd.concat(future_exog, axis=1)\n",
    "        future_exog.columns = exog_vars\n",
    "\n",
    "        future_preds = exp.predict_model(model, X=future_exog)\n",
    "\n",
    "    return future_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_preds = safe_predict(exp_auto, final_auto_model)\n",
    "future_preds.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(plot = 'auc', save=True)\n",
    "exp.plot_model(plot = 'confusion_matrix', save=True)\n",
    "exp.plot_model(plot = 'vc', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final_auto_model\n",
    "exp_auto.save_model(final_auto_model, \"final_auto_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "85f098b8f4fe820e63469efe3fc7afef88f306802598cd06f3cad1315254cba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
