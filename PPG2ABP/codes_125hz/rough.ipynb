{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data_processing import process_data\n",
    "\n",
    "# show the version of pytorch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mat file using hdf5\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('raw_data/Part_1.mat', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f), list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f['Part_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f[f['Part_1'][99][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[f['Part_1'][99][0]][69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read kaggle mat file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mat file\n",
    "from scipy.io import loadmat \n",
    "mat = loadmat('raw_data_k/part_1.mat')['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mat[0][99][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67.06295517, 69.35862807, 75.36645289, ..., 76.44102319,\n",
       "       81.81387466, 91.38731909])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = mat[0][99][1].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.21110750243585"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = 125\t\t\t\t\t\t\t\t# sampling frequency\n",
    "t = 10\t\t\t\t\t\t\t\t\t# length of ppg episodes\n",
    "dt = 5\t\t\t\t\t\t\t\t\t# step size of taking the next episode\n",
    "\n",
    "samples_in_episode = round(fs * t)\n",
    "\n",
    "\n",
    "max(bp[0:0 + samples_in_episode])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "candidates = pickle.load(open('candidates.p', 'rb'))\n",
    "\n",
    "record_no = int(candidates[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.1117337100187"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0][record_no][1][69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_dataprocessing import process_data\n",
    "\n",
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import process_data\n",
    "\n",
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import observe_processed_data\n",
    "\n",
    "observe_processed_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import downsample_data\n",
    "\n",
    "downsample_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'ppgs'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'abps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from Files:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from kaggle_dataprocessing import extract_episodes\n",
    "import pickle\n",
    "\n",
    "candidates = pickle.load(open('candidates.p', 'rb'))\n",
    "extract_episodes(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2075/2075 [00:23<00:00, 88.97it/s] \n"
     ]
    }
   ],
   "source": [
    "from kaggle_dataprocessing import merge_episodes\n",
    "\n",
    "merge_episodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folding Data:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Training Data Part 1:   8%|▊         | 7245/90000 [00:13<02:39, 519.30it/s]\n",
      "Folding Data:   0%|          | 0/10 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_handling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fold_data\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfold_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\Documents\\ABP-estimation-using-PPG\\other\\PPG2ABP\\codes\\data_handling.py:54\u001b[0m, in \u001b[0;36mfold_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m val_start \u001b[39m=\u001b[39m validation_data_start[fold_id]      \u001b[39m# validation data start\u001b[39;00m\n\u001b[0;32m     52\u001b[0m val_end \u001b[39m=\u001b[39m val_start \u001b[39m+\u001b[39m \u001b[39m10000\u001b[39m                     \u001b[39m# validation data end\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, val_start), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining Data Part 1\u001b[39m\u001b[39m'\u001b[39m):    \u001b[39m# training samples before validation samples\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     X_train\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39marray(fl[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m1\u001b[39m][:length])\u001b[39m.\u001b[39mreshape(length, \u001b[39m1\u001b[39m))  \u001b[39m# ppg signal\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     Y_train\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39marray(fl[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m0\u001b[39m][:length])\u001b[39m.\u001b[39mreshape(length, \u001b[39m1\u001b[39m))  \u001b[39m# abp signal\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m dt \u001b[39m=\u001b[39m cur_t \u001b[39m-\u001b[39m last_print_t\n\u001b[0;32m   1194\u001b[0m \u001b[39mif\u001b[39;00m dt \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m mininterval \u001b[39mand\u001b[39;00m cur_t \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m min_start_t:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(n \u001b[39m-\u001b[39;49m last_print_n)\n\u001b[0;32m   1196\u001b[0m     last_print_n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_print_n\n\u001b[0;32m   1197\u001b[0m     last_print_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_print_t\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\std.py:1246\u001b[0m, in \u001b[0;36mtqdm.update\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ema_dn(dn)\n\u001b[0;32m   1245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ema_dt(dt)\n\u001b[1;32m-> 1246\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrefresh(lock_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlock_args)\n\u001b[0;32m   1247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_miniters:\n\u001b[0;32m   1248\u001b[0m     \u001b[39m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m     \u001b[39m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m     \u001b[39m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m     \u001b[39m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m     \u001b[39m# at least 5 more iterations.\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxinterval \u001b[39mand\u001b[39;00m dt \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxinterval:\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\std.py:1351\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39macquire()\n\u001b[1;32m-> 1351\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisplay()\n\u001b[0;32m   1352\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nolock:\n\u001b[0;32m   1353\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\std.py:1498\u001b[0m, in \u001b[0;36mtqdm.display\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     \u001b[39mraise\u001b[39;00m TqdmDeprecationWarning(\n\u001b[0;32m   1493\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use `tqdm.gui.tqdm(...)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1494\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m instead of `tqdm(..., gui=True)`\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         fp_write\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp, \u001b[39m'\u001b[39m\u001b[39mwrite\u001b[39m\u001b[39m'\u001b[39m, sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite))\n\u001b[0;32m   1497\u001b[0m \u001b[39mif\u001b[39;00m pos:\n\u001b[1;32m-> 1498\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmoveto(pos)\n\u001b[0;32m   1499\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__str__\u001b[39m() \u001b[39mif\u001b[39;00m msg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m msg)\n\u001b[0;32m   1500\u001b[0m \u001b[39mif\u001b[39;00m pos:\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\std.py:1447\u001b[0m, in \u001b[0;36mtqdm.moveto\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmoveto\u001b[39m(\u001b[39mself\u001b[39m, n):\n\u001b[0;32m   1446\u001b[0m     \u001b[39m# TODO: private method\u001b[39;00m\n\u001b[1;32m-> 1447\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mwrite(_unicode(\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m*\u001b[39;49m n \u001b[39m+\u001b[39;49m _term_move_up() \u001b[39m*\u001b[39;49m \u001b[39m-\u001b[39;49mn))\n\u001b[0;32m   1448\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\utils.py:145\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    146\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    147\u001b[0m         \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m \u001b[39m5\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\iostream.py:519\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    517\u001b[0m is_child \u001b[39m=\u001b[39m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_master_process())\n\u001b[0;32m    518\u001b[0m \u001b[39m# only touch the buffer in the IO thread to avoid races\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(\u001b[39mlambda\u001b[39;49;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mwrite(string))\n\u001b[0;32m    520\u001b[0m \u001b[39mif\u001b[39;00m is_child:\n\u001b[0;32m    521\u001b[0m     \u001b[39m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[39;00m\n\u001b[0;32m    522\u001b[0m     \u001b[39m# and this helps.\u001b[39;00m\n\u001b[0;32m    523\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subprocess_flush_pending:\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\iostream.py:214\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[0;32m    213\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     f()\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\zmq\\sugar\\socket.py:618\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    611\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[0;32m    612\u001b[0m             data,\n\u001b[0;32m    613\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[0;32m    614\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    615\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[0;32m    616\u001b[0m         )\n\u001b[0;32m    617\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[1;32m--> 618\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:740\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:787\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:244\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\anaconda3\\envs\\ml\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from data_handling import fold_data\n",
    "\n",
    "fold_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Training Fold 1\n",
      "----------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\train0.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_approximate_network\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrain_approximate_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LuckyVerma\\Documents\\ABP-estimation-using-PPG\\other\\PPG2ABP\\codes\\train_models.py:55\u001b[0m, in \u001b[0;36mtrain_approximate_network\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m----------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     54\u001b[0m                                                                                     \u001b[39m# loading training data\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m dt \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m.p\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(foldname)),\u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     56\u001b[0m X_train \u001b[39m=\u001b[39m dt[\u001b[39m'\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     57\u001b[0m Y_train \u001b[39m=\u001b[39m dt[\u001b[39m'\u001b[39m\u001b[39mY_train\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\train0.p'"
     ]
    }
   ],
   "source": [
    "from helper_functions import *\n",
    "from models import *\n",
    "from train_models import train_approximate_network\n",
    "\n",
    "train_approximate_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bunnies')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85f098b8f4fe820e63469efe3fc7afef88f306802598cd06f3cad1315254cba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
